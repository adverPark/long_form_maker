#!/usr/bin/env python3
"""
ì—°ì†ìœ¼ë¡œ ë¹„ì •ìƒì ìœ¼ë¡œ ë¹ ë¥¸ ìë§‰ ê°ì§€
- 30ë²ˆ ì”¬ì²˜ëŸ¼ ì˜¤ë””ì˜¤ê°€ ì˜ë¦¬ê³  WhisperXê°€ í™˜ê°ì„ ì¼ìœ¼í‚¨ ê²½ìš° íƒì§€
- ê°œë³„ ì§§ì€ ë‹¨ì–´ê°€ ì•„ë‹Œ, ì—°ì†ìœ¼ë¡œ ë¹ ë¥¸ ë‹¨ì–´ë“¤ì„ ì°¾ìŒ
"""
import os
import re
from pathlib import Path

def parse_srt_time(time_str):
    """SRT ì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜"""
    time_str = time_str.replace(',', '.')
    match = re.match(r'(\d{2}):(\d{2}):(\d{2})\.(\d{3})', time_str)
    if match:
        h, m, s, ms = match.groups()
        return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
    return 0

def analyze_srt(filepath):
    """SRT íŒŒì¼ ë¶„ì„ - ì—°ì† ë¹ ë¥¸ ìë§‰ ê°ì§€"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # SRT ë¸”ë¡ íŒŒì‹±
    blocks = re.split(r'\n\n+', content.strip())
    entries = []
    
    for block in blocks:
        lines = block.strip().split('\n')
        if len(lines) >= 3:
            timing_match = re.match(
                r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})',
                lines[1]
            )
            if timing_match:
                start = parse_srt_time(timing_match.group(1))
                end = parse_srt_time(timing_match.group(2))
                text = ' '.join(lines[2:]).strip()
                duration = end - start
                entries.append({
                    'start': start,
                    'end': end,
                    'duration': duration,
                    'text': text
                })
    
    if not entries:
        return None
    
    # ì—°ì† ë¹ ë¥¸ ìë§‰ ì°¾ê¸° (3ê°œ ì´ìƒ ì—°ì†ìœ¼ë¡œ 0.15ì´ˆ ë¯¸ë§Œ)
    consecutive_fast = []
    current_streak = []
    
    for i, entry in enumerate(entries):
        if entry['duration'] < 0.15:  # 150ms ë¯¸ë§Œ
            current_streak.append((i + 1, entry))
        else:
            if len(current_streak) >= 3:  # 3ê°œ ì´ìƒ ì—°ì†
                consecutive_fast.append(current_streak.copy())
            current_streak = []
    
    # ë§ˆì§€ë§‰ ìŠ¤íŠ¸ë¦­ ì²´í¬
    if len(current_streak) >= 3:
        consecutive_fast.append(current_streak)
    
    # í›„ë°˜ë¶€ì— ì§‘ì¤‘ëœ ë¹ ë¥¸ ìë§‰ (ì˜¤ë””ì˜¤ ì˜ë¦¼ ì§•í›„)
    # ë§ˆì§€ë§‰ 30%ì—ì„œ í‰ê·  ì†ë„ê°€ ì „ë°˜ë¶€ë³´ë‹¤ 3ë°° ì´ìƒ ë¹ ë¥´ë©´ ì˜ì‹¬
    if len(entries) >= 5:
        split_point = int(len(entries) * 0.7)
        first_part = entries[:split_point]
        last_part = entries[split_point:]
        
        if first_part and last_part:
            first_avg = sum(e['duration'] for e in first_part) / len(first_part)
            last_avg = sum(e['duration'] for e in last_part) / len(last_part)
            
            if first_avg > 0 and last_avg > 0 and first_avg / last_avg > 3:
                return {
                    'type': 'tail_compression',
                    'total_entries': len(entries),
                    'first_avg_ms': int(first_avg * 1000),
                    'last_avg_ms': int(last_avg * 1000),
                    'ratio': round(first_avg / last_avg, 1),
                    'last_entries': [(i + split_point + 1, e['text'], int(e['duration'] * 1000)) 
                                     for i, e in enumerate(last_part)]
                }
    
    if consecutive_fast:
        return {
            'type': 'consecutive_fast',
            'streaks': [
                {
                    'count': len(streak),
                    'entries': [(idx, e['text'], int(e['duration'] * 1000)) for idx, e in streak]
                }
                for streak in consecutive_fast
            ]
        }
    
    return None

# ë¯¸ë””ì–´ ë””ë ‰í† ë¦¬ ìŠ¤ìº”
media_root = Path('/home/adver/long_form_site/media/projects')
srt_files = list(media_root.glob('**/subtitles/*.srt'))

print(f"ì´ {len(srt_files)}ê°œ SRT íŒŒì¼ ë¶„ì„ ì¤‘...\n")

problematic = []

for srt_path in sorted(srt_files):
    result = analyze_srt(srt_path)
    if result:
        # í”„ë¡œì íŠ¸ ë²ˆí˜¸ì™€ ì”¬ ë²ˆí˜¸ ì¶”ì¶œ
        parts = str(srt_path).split('/')
        project_id = parts[-3] if len(parts) >= 3 else 'unknown'
        scene_name = srt_path.stem
        
        problematic.append({
            'path': str(srt_path),
            'project': project_id,
            'scene': scene_name,
            'result': result
        })

print(f"ğŸš¨ ë¬¸ì œ ë°œê²¬: {len(problematic)}ê°œ íŒŒì¼\n")
print("=" * 80)

for item in problematic:
    print(f"\nğŸ“ í”„ë¡œì íŠ¸ {item['project']} / {item['scene']}")
    print(f"   ê²½ë¡œ: {item['path']}")
    
    result = item['result']
    if result['type'] == 'tail_compression':
        print(f"   âš ï¸  í›„ë°˜ë¶€ ì••ì¶• ê°ì§€!")
        print(f"      ì „ì²´ {result['total_entries']}ê°œ ë‹¨ì–´")
        print(f"      ì „ë°˜ë¶€ í‰ê· : {result['first_avg_ms']}ms")
        print(f"      í›„ë°˜ë¶€ í‰ê· : {result['last_avg_ms']}ms (ì „ë°˜ë¶€ì˜ 1/{result['ratio']})")
        print(f"      í›„ë°˜ë¶€ ë‹¨ì–´:")
        for idx, text, dur in result['last_entries'][:5]:
            print(f"         #{idx}: {text} â†’ {dur}ms")
        if len(result['last_entries']) > 5:
            print(f"         ... ì™¸ {len(result['last_entries']) - 5}ê°œ")
    
    elif result['type'] == 'consecutive_fast':
        for streak in result['streaks']:
            print(f"   âš ï¸  ì—°ì† {streak['count']}ê°œ ë¹ ë¥¸ ìë§‰:")
            for idx, text, dur in streak['entries'][:5]:
                print(f"      #{idx}: {text} â†’ {dur}ms")
            if len(streak['entries']) > 5:
                print(f"      ... ì™¸ {len(streak['entries']) - 5}ê°œ")

print("\n" + "=" * 80)
